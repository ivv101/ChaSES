{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    " \n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "  \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request \n",
    "\n",
    "import magic\n",
    "\n",
    "from sklearn.cluster import DBSCAN, OPTICS #, KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from kneed import KneeLocator # https://github.com/arvkevi/kneed\n",
    "\n",
    "import warnings\n",
    "\n",
    "from scipy.spatial import ConvexHull, distance_matrix #, Delaunay, distance\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from pca import pca # https://github.com/erdogant/pca\n",
    "\n",
    "# from ciao_contrib.runtool import new_pfiles_environment, dmcoords\n",
    "\n",
    "# import json\n",
    "# import pickle as pkl\n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_nans = lambda x : x[~np.isnan(np.sum(x, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from expanded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evt2_file(obsid, path='.'):\n",
    "    '''\n",
    "    We assume that there exists a single evt2 file in primary directory in CXC database\n",
    "    '''\n",
    "    \n",
    "    status = 'ok'\n",
    "    \n",
    "    # folders organized by last digit of obsid\n",
    "    last = str(obsid)[-1]\n",
    "    primary_url = f'https://cxc.cfa.harvard.edu/cdaftp/byobsid/{last}/{str(obsid)}/primary'\n",
    "    \n",
    "    _ = glob.glob(f'{path}/*{int(obsid):05d}*')\n",
    "    if _: return status, f'{primary_url}/{os.path.basename(_[0])}', _[0]\n",
    "    \n",
    "    html_text = requests.get(primary_url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    \n",
    "    evt2_list = [_.get('href') for _ in soup.find_all('a') if re.search(r'evt2', _.get('href'))]\n",
    "    if len(evt2_list) != 1:\n",
    "        print(f'Error: there are {len(evt2_list)} evt2 files: {evt2_list}')\n",
    "        status = f'{len(evt2_list)} evt2 files: {evt2_list}'\n",
    "        \n",
    "    evt2_filename = evt2_list[0]\n",
    "                \n",
    "    urllib.request.urlretrieve(f'{primary_url}/{evt2_filename}', f'{path}/{evt2_filename}')\n",
    "    \n",
    "    return status, f'{primary_url}/{evt2_filename}', f'{path}/{evt2_filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fits(fn):\n",
    "    \n",
    "    with fits.open(fn) as _:\n",
    "        head = _[1].header\n",
    "        evt2_data = _[1].data\n",
    "    \n",
    "    return evt2_data, head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_filter_evt2(evt2_data):\n",
    "    \n",
    "    X = evt2_data\n",
    "    \n",
    "    cols = ['ccd_id', 'x', 'y', 'energy']\n",
    "    \n",
    "    mask = (500 < X['energy']) & (X['energy'] < 8000)\n",
    "    \n",
    "    X = Table(X)[mask][cols].to_pandas()\n",
    "    \n",
    "    ccds = np.unique(X['ccd_id'].tolist())\n",
    "    \n",
    "    xy = {}\n",
    "    \n",
    "    for ccd, data in X.groupby('ccd_id'):\n",
    "    \n",
    "        xy[f'ccd_{ccd}'] = remove_nans(data[['x', 'y']].values).astype(None) \n",
    "    \n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_obsid_data(obsid, evt2_dir, evt2_size_limit=np.inf):\n",
    "\n",
    "    status, url, fn = get_evt2_file(obsid, evt2_dir)\n",
    "    \n",
    "    if status != 'ok':\n",
    "        return status, 0, 0\n",
    "        \n",
    "    if os.stat(fn).st_size > evt2_size_limit * 2**20:        \n",
    "        return f'{obsid} too big\\n', 0, 0\n",
    "\n",
    "    evt2_data, evt2_head = process_fits(fn)\n",
    "    \n",
    "    evt2_info = {\n",
    "        'exp': evt2_head['EXPOSURE'] / 1000,\n",
    "        'obsid': obsid,\n",
    "        'url': url        \n",
    "    }\n",
    "\n",
    "    xy = xy_filter_evt2(evt2_data)\n",
    "            \n",
    "    return status, xy, evt2_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = lambda fn : magic.Magic(mime_encoding=True).from_file(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OBSIDs(fn, encoding=''):\n",
    "\n",
    "    # fn = f'All_OBSIDs_ACIS-{name}.csv'\n",
    "    \n",
    "    if encoding=='':\n",
    "        encoding = detect(fn)\n",
    "    \n",
    "    df = pd.read_csv(fn, engine='python', encoding=encoding)\n",
    "\n",
    "    fl = df['Galactic l'].apply(lambda _ : f'{_:.1f}')\n",
    "    fb = df['Galactic b'].apply(lambda _ : f'{_:.1f}')\n",
    "\n",
    "    df['Galactic lb label'] = [l + '_' + b for l, b in zip(fl, fb)]\n",
    "\n",
    "    df = df.set_index('Obs ID')\n",
    "\n",
    "    gb = df.groupby('Galactic lb label')\n",
    "\n",
    "    gbval = list(gb.groups.values())\n",
    "\n",
    "    OBSIDs = []\n",
    "\n",
    "    # for same 'Galactic l' and 'Galactic b' we choose obsid with largest exposure\n",
    "\n",
    "    for _ in gbval:\n",
    "        if len(_) == 1:\n",
    "            OBSIDs.append(_[0])\n",
    "        else:\n",
    "            OBSIDs.append(df.loc[_]['Exposure '].idxmax())\n",
    "\n",
    "    return OBSIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from expanded_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(xys, n_jobs=1, algorithm='dbscan'):\n",
    "    '''\n",
    "    returns indices of clusters (-1(noise))\n",
    "    '''\n",
    "    \n",
    "    X = StandardScaler().fit_transform(xys)\n",
    "    \n",
    "    eps = 4 * np.sqrt(4 / len(X))\n",
    "    \n",
    "    if algorithm == 'optics':   \n",
    "\n",
    "        db = OPTICS(eps=float(eps), n_jobs=n_jobs).fit_predict(X) \n",
    "\n",
    "        return db\n",
    "    \n",
    "    ncl=[]\n",
    "    nsmpl=[]\n",
    "                    \n",
    "    for i in range(1, 20):\n",
    "\n",
    "        pts = 1 + pow(len(X), i / 40) # pow(10, i*math.log10(len(X))/40.0)\n",
    "\n",
    "        if algorithm == 'dbscan':\n",
    "\n",
    "            db = DBSCAN(eps=eps, min_samples=pts, n_jobs=n_jobs).fit(X)\n",
    "\n",
    "        elif algorithm == 'hdbscan':   \n",
    "\n",
    "            db = hdbscan.HDBSCAN(cluster_selection_epsilon=float(eps), \n",
    "                                 min_samples=int(pts),\n",
    "                                 core_dist_n_jobs=1).fit(X) \n",
    "\n",
    "        else:\n",
    "\n",
    "            return 'incorrect algorithm'\n",
    "\n",
    "        n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "\n",
    "        ncl.append(n_clusters_)\n",
    "        nsmpl.append(pts)\n",
    "        \n",
    "    index_max = np.argmax(ncl) \n",
    "    \n",
    "    if index_max == len(ncl) - 1:\n",
    "        return 'bad knee'\n",
    "    \n",
    "#     print(index_max, len(nsmpl), len(ncl), nsmpl[index_max:], ncl[index_max:], ncl)\n",
    "        \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error')\n",
    "        try:\n",
    "            kn = KneeLocator(nsmpl[index_max:], ncl[index_max:], curve='convex', direction='decreasing')\n",
    "        except:\n",
    "            return 'bad knee'\n",
    "        \n",
    "    if algorithm == 'dbscan':\n",
    "        \n",
    "        db = DBSCAN(eps=eps, min_samples=np.floor(kn.knee), n_jobs=n_jobs).fit_predict(X)\n",
    "        \n",
    "    elif algorithm == 'hdbscan':   \n",
    "\n",
    "        db = hdbscan.HDBSCAN(cluster_selection_epsilon=float(eps), \n",
    "                             min_samples=int(np.floor(kn.knee)),\n",
    "                             core_dist_n_jobs=1).fit_predict(X)     \n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_minpts(xys, n_jobs=1, algorithm='dbscan', minpts=False):\n",
    "    '''\n",
    "    returns indices of clusters (-1(noise))\n",
    "    '''\n",
    "    \n",
    "    if algorithm != 'hdbscan' or not minpts:\n",
    "        find_clusters(xys, n_jobs=n_jobs, algorithm=algorithm)\n",
    "        return\n",
    "    \n",
    "    X = StandardScaler().fit_transform(xys)\n",
    "    \n",
    "    lst = np.sort(list(set(np.logspace(np.log10(3), np.log10(len(X)/100), 50).astype(int))))\n",
    "    \n",
    "    zzz = []\n",
    "\n",
    "    for i in lst:\n",
    "\n",
    "        db = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=int(i),\n",
    "            core_dist_n_jobs=1).fit(X) \n",
    "\n",
    "        _ = np.sum(db.labels_==-1)\n",
    "\n",
    "        zzz.append([int(i), _])\n",
    "\n",
    "    min_cluster_size = zzz[np.argmin(np.transpose(zzz)[1])][0]\n",
    "    \n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                         core_dist_n_jobs=1).fit(X) \n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def find_clusters_obsid(data_file, pkl_data_size_limit, algorithm='dbscan', minpts=False):\n",
    "    \n",
    "#     t = timer()           \n",
    "    \n",
    "    sz = os.stat(data_file).st_size / 2**20\n",
    "    \n",
    "    if sz > pkl_data_size_limit:\n",
    "        \n",
    "#         print(f'too big: {sz:.2f} MB')\n",
    "        \n",
    "        status = 'too big'\n",
    "    \n",
    "        # print(status)    \n",
    "        return status, {}\n",
    "                        \n",
    "    data = pkl.load(open(data_file, 'rb'))\n",
    "    \n",
    "    status = data['status']\n",
    "    \n",
    "    if status != 'ok':\n",
    "        print(status)     \n",
    "        return status, {}\n",
    "        \n",
    "    clusters = {}        \n",
    "    \n",
    "    for ccd, ccd_data in data['xy'].items():\n",
    "        \n",
    "        # print(ccd_data)\n",
    "        \n",
    "#         if np.isnan(np.sum(ccd_data)):\n",
    "            \n",
    "#             clusters[ccd] = 'nan'\n",
    "#             status = 'nan'\n",
    "            \n",
    "#         else:    \n",
    "\n",
    "        clusters[ccd] = find_clusters_minpts(ccd_data, n_jobs=1, algorithm=algorithm, minpts=minpts)\n",
    "\n",
    "        if isinstance(clusters[ccd], str): \n",
    "            status = 'bad knee'   \n",
    "        \n",
    "    return status, clusters  \n",
    "        \n",
    "#     print(f'{timer() - t:.2f} sec')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from expanded_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot2d(phi):\n",
    "    return np.array([[np.cos(phi), -np.sin(phi)], \n",
    "                    [np.sin(phi),  np.cos(phi)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(xp, yp, decimals=None):\n",
    "    \n",
    "    pts = np.array([xp, yp]).T\n",
    "    \n",
    "    hull = ConvexHull(pts)\n",
    "    hull = pts[hull.vertices]\n",
    "\n",
    "    areas = np.array([])\n",
    "    phis = np.array([])\n",
    "\n",
    "    for i, vert in enumerate(hull):\n",
    "\n",
    "        nxt = i + 1\n",
    "        if nxt == len(hull):\n",
    "            nxt = 0\n",
    "\n",
    "        edge = hull[nxt] - vert   \n",
    "\n",
    "        phi = np.arctan2(edge[1], edge[0])\n",
    "        phis = np.append(phis, phi)\n",
    "        \n",
    "        xy = np.dot(rot2d(-phi), (hull - vert).T)\n",
    "\n",
    "        area = (max(xy[0]) - min(xy[0])) * (max(xy[1]) - min(xy[1]))\n",
    "        areas = np.append(areas, area)\n",
    "\n",
    "    ind = np.argmin(areas)  \n",
    "\n",
    "    x, y = np.dot(rot2d(-phis[ind]), (pts - hull[ind]).T)\n",
    "\n",
    "    xmin, xmax, ymin, ymax = min(x), max(x), min(y), max(y)\n",
    "\n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "\n",
    "    if dx < dy:\n",
    "        xs = (x - xmin + (dy - dx) / 2) / dy\n",
    "        ys = (y - ymin) / dy\n",
    "        dxdy = True\n",
    "    else:        \n",
    "        xs = (x - xmin) / dx\n",
    "        ys = (y - ymin + (dx - dy) / 2) / dx\n",
    "        dxdy = False\n",
    "\n",
    "    if decimals != None:\n",
    "        xs = np.around(xs, decimals=decimals)\n",
    "        ys = np.around(ys, decimals=decimals)\n",
    "                \n",
    "    X = np.transpose([xs, ys])    \n",
    "    X = (X - X.min(0)) / (X.max(0) - X.min(0))\n",
    "    \n",
    "    out = {\n",
    "        'pars': {\n",
    "            'phi': phis[ind],\n",
    "            'offset': hull[ind].tolist(),\n",
    "            'xmin': xmin,\n",
    "            'xmax': xmax,\n",
    "            'ymin': ymin,\n",
    "            'ymax': ymax,\n",
    "            'dx<dy': dxdy,\n",
    "            'X.min(0)': X.min(0),\n",
    "            'dX(0)': X.max(0) - X.min(0),\n",
    "            \n",
    "        },\n",
    "        'x': xs,\n",
    "        'y': ys,\n",
    "        'X': X\n",
    "    }\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pars(xp, yp, pars, decimals=None):\n",
    "    \n",
    "    nms = ['phi', 'offset', 'xmin', 'xmax', 'ymin', 'ymax', 'dx<dy', 'X.min(0)', 'dX(0)']\n",
    "    \n",
    "    phi, offset, xmin, xmax, ymin, ymax, dxdy, Xmin0, dX0 = [pars[_] for _ in nms]\n",
    "        \n",
    "    pts = np.array([xp, yp]).T\n",
    "    \n",
    "    x, y = np.dot(rot2d(-phi), (pts - offset).T)\n",
    "\n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "\n",
    "    if dxdy:\n",
    "        xs = (x - xmin + (dy - dx) / 2) / dy\n",
    "        ys = (y - ymin) / dy\n",
    "    else:        \n",
    "        xs = (x - xmin) / dx\n",
    "        ys = (y - ymin + (dx - dy) / 2) / dx\n",
    "\n",
    "    if decimals != None:\n",
    "        xs = np.around(xs, decimals=decimals)\n",
    "        ys = np.around(ys, decimals=decimals)\n",
    "        \n",
    "    X = np.transpose([xs, ys])    \n",
    "    X = (X - Xmin0) / dX0\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale(xs, ys, pars):\n",
    "        \n",
    "    nms = ['phi', 'offset', 'xmin', 'xmax', 'ymin', 'ymax', 'dx<dy', 'X.min(0)', 'dX(0)']\n",
    "    \n",
    "    phi, offset, xmin, xmax, ymin, ymax, dxdy, Xmin0, dX0 = [pars[_] for _ in nms]\n",
    "    \n",
    "    x, y = (np.transpose([xs, ys]) * dX0 + Xmin0).T\n",
    "                                                             \n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "                \n",
    "    if dxdy:\n",
    "        xp = x * dy + xmin - (dy - dx) / 2\n",
    "        yp = y * dy + ymin\n",
    "    else:\n",
    "        xp = x * dx + xmin\n",
    "        yp = y * dx + ymin - (dx - dy) / 2\n",
    "            \n",
    "    xy = np.dot(rot2d(phi), np.array([xp, yp])).T\n",
    "    \n",
    "    return (xy + offset).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_shape(points, alpha, only_outer=True):\n",
    "    \"\"\"\n",
    "    Compute the alpha shape (concave hull) of a set of points.\n",
    "    :param points: np.array of shape (n,2) points.\n",
    "    :param alpha: alpha value.\n",
    "    :param only_outer: boolean value to specify if we keep only the outer border\n",
    "    or also inner edges.\n",
    "    :return: set of (i,j) pairs representing edges of the alpha-shape. (i,j) are\n",
    "    the indices in the points array.\n",
    "    \"\"\"\n",
    "    assert points.shape[0] > 3, \"Need at least four points\"\n",
    "\n",
    "    def add_edge(edges, i, j):\n",
    "        \"\"\"\n",
    "        Add a line between the i-th and j-th points,\n",
    "        if not in the list already\n",
    "        \"\"\"\n",
    "        if (i, j) in edges or (j, i) in edges:\n",
    "            # already added\n",
    "            assert (j, i) in edges, \"Can't go twice over same directed edge right?\"\n",
    "            if only_outer:\n",
    "                # if both neighboring triangles are in shape, it's not a boundary edge\n",
    "                edges.remove((j, i))\n",
    "            return\n",
    "        edges.add((i, j))\n",
    "\n",
    "    tri = Delaunay(points)\n",
    "    edges = set()\n",
    "    # Loop over triangles:\n",
    "    # ia, ib, ic = indices of corner points of the triangle\n",
    "    for ia, ib, ic in tri.vertices:\n",
    "        pa = points[ia]\n",
    "        pb = points[ib]\n",
    "        pc = points[ic]\n",
    "        # Computing radius of triangle circumcircle\n",
    "        # www.mathalino.com/reviewer/derivation-of-formulas/derivation-of-formula-for-radius-of-circumcircle\n",
    "        a = np.sqrt((pa[0] - pb[0]) ** 2 + (pa[1] - pb[1]) ** 2)\n",
    "        b = np.sqrt((pb[0] - pc[0]) ** 2 + (pb[1] - pc[1]) ** 2)\n",
    "        c = np.sqrt((pc[0] - pa[0]) ** 2 + (pc[1] - pa[1]) ** 2)\n",
    "        s = (a + b + c) / 2.0\n",
    "        area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        circum_r = a * b * c / (4.0 * area)\n",
    "        if circum_r < alpha:\n",
    "            add_edge(edges, ia, ib)\n",
    "            add_edge(edges, ib, ic)\n",
    "            add_edge(edges, ic, ia)\n",
    "    return np.array(list(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ConvexHull(cluster):\n",
    "    \n",
    "    hull = ConvexHull(cluster)\n",
    "        \n",
    "    vert = hull.vertices\n",
    "    \n",
    "    return  cluster[np.append(vert, vert[:1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lasso(cluster, alpha=0.02):\n",
    "         \n",
    "    try:\n",
    "        \n",
    "        cs = scale(*c.T)\n",
    "        cs = np.transpose([cs['x'], cs['y']])\n",
    "        \n",
    "        lasso = alpha_shape(cs, alpha=alpha, only_outer=True)\n",
    "        \n",
    "        lasso_dict = dict(zip(*lasso.T))\n",
    "\n",
    "        out = [list(lasso_dict.keys())[0]]\n",
    "\n",
    "        nxt = -1\n",
    "\n",
    "        while nxt != out[0]:\n",
    "\n",
    "            nxt = lasso_dict.pop(out[-1])\n",
    "            out.append(nxt)\n",
    "\n",
    "        out = np.array(out).astype(int)\n",
    "\n",
    "        if len(lasso_dict) > 0:\n",
    "            \n",
    "            print(f'Warning: non-continuous cluster: {len(lasso_dict)} remaining edges')\n",
    "            \n",
    "#             return 'convex_hull', find_ConvexHull(cluster)\n",
    "            \n",
    "        return 'alpha_shape', cluster[out]\n",
    "        \n",
    "    except:\n",
    "                        \n",
    "        return 'convex_hull', find_ConvexHull(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bkg_density(xys, cl, clusters_idx):\n",
    "    \n",
    "    ccd_npoints = len(xys)\n",
    "    ccd_area_px = ConvexHull(xys).volume   \n",
    "    all_sources_area_px = np.sum([_['area_px'] for _ in cl])\n",
    "    noise_npoints = np.sum(clusters_idx==-1)\n",
    "    \n",
    "#     print(noise_npoints, ccd_area_px, all_sources_area_px)\n",
    "\n",
    "    bkg_density_px = noise_npoints / (ccd_area_px - all_sources_area_px)\n",
    "    \n",
    "    return bkg_density_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_images(data, an, obsid, img_dir, debug_mode=False, is_interactive=False):\n",
    "    \n",
    "    arr = np.concatenate(list(data['xy'].values())).T\n",
    "    \n",
    "    xx, yy = arr\n",
    "\n",
    "    xmin, xmax, ymin, ymax = xx.min(), xx.max(), yy.min(), yy.max()\n",
    "\n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "\n",
    "    bounds = xmin, xmax, ymin, ymax\n",
    "\n",
    "    data = np.histogram2d(*arr, bins=250)[0]\n",
    "    data = gaussian_filter(data, sigma=0.5)\n",
    "\n",
    "    fig, ax = plt.subplots(facecolor='k', figsize=(10, 10*h/w))\n",
    "\n",
    "    cmap = 'Blues_r'\n",
    "    plt.pcolormesh(np.log(data + 1).T, cmap=cmap, shading='flat')\n",
    "\n",
    "    if debug_mode & (an['status'] == 'ok'):\n",
    "        for ccd, v in an['data'].items():\n",
    "            for i, k in enumerate(v['clusters']):\n",
    "\n",
    "                x, y = np.transpose(k['lasso'][1])\n",
    "                \n",
    "                x = 250 * (x - xmin) / (xmax - xmin)\n",
    "                y = 250 * (y - ymin) / (ymax - ymin)\n",
    "\n",
    "                col = 'y' if k['status'] == 'ok' else 'r'   \n",
    "\n",
    "#                 lab = ''.join([f'{_} = {lassos_info[ccd][i][_]:.2f}\\n' for _ in ['roundness', 'area', 'area_psf', 'area_px']])     \n",
    "\n",
    "                ax.plot(x, y, c=col)\n",
    "\n",
    "    #             ax.fill(x, y, c=col, alpha=0)\n",
    "\n",
    "#     ax.set_aspect(1)\n",
    "    plt.axis('off') \n",
    "    ax.get_xaxis().set_visible(False) \n",
    "    ax.get_yaxis().set_visible(False) \n",
    "    \n",
    "    _ = '_debug' if debug_mode else ''    \n",
    "    plt.savefig(f'{img_dir}/{obsid}{_}.jpeg', bbox_inches='tight', pad_inches = 0) \n",
    "\n",
    "#     mplcursors.cursor(hover=True).connect(\n",
    "#         \"add\", lambda sel: sel.annotation.set_text(sel.artist.get_label()))\n",
    "\n",
    "    if is_interactive: plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "#     fig, ax = plt.subplots(facecolor='k', figsize=(10, 10*h/w))\n",
    "\n",
    "#     [ax.scatter(*xy_unscaled[ccd], s=0.1, c=[[56/255, 117/255, 174/255]]) for ccd in xy_unscaled.keys()]\n",
    "    \n",
    "#     if debug_mode:\n",
    "#         for ccd, v in lassos_unscaled.items():\n",
    "#             for i, lasso in enumerate(v):\n",
    "\n",
    "#                 col = 'y' if lassos_info[ccd][i]['is_good'] else 'r'    \n",
    "\n",
    "#                 ax.plot(*lasso[1].T, c=col)\n",
    "\n",
    "#         ax.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin], c='r')\n",
    "\n",
    "#     ax.set_xlim(xmin, xmax)\n",
    "#     ax.set_ylim(ymin, ymax)\n",
    "\n",
    "#     plt.axis('off') \n",
    "#     ax.get_xaxis().set_visible(False) \n",
    "#     ax.get_yaxis().set_visible(False) \n",
    "\n",
    "#     plt.savefig(f'{webdata_dir}/{obsid}_alt.jpeg', bbox_inches='tight', pad_inches = 0) \n",
    "\n",
    "#     if is_interactive: plt.show()\n",
    "        \n",
    "#     plt.close()\n",
    "    \n",
    "    return bounds # make_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def get_web_entry(data, an, bounds, w_jpg, h_jpg, debug_mode):\n",
    "\n",
    "    xmin, xmax, ymin, ymax = bounds\n",
    "    \n",
    "    web = {}\n",
    "    \n",
    "    obsid = str(data['info']['obsid'])\n",
    "    \n",
    "    web['obsid'] = obsid\n",
    "    \n",
    "    web['box_x'] = w_jpg\n",
    "    web['box_y'] = h_jpg\n",
    "    \n",
    "    web['exp'] = f\"{data['info']['exp']:.2f}\"\n",
    "        \n",
    "    web['url'] = data['info']['url']\n",
    "        \n",
    "    web['lassos'] = {}\n",
    "        \n",
    "    for ccd, v in an['data'].items():\n",
    "                \n",
    "        for i, info in enumerate(v['clusters']):\n",
    "            \n",
    "            if (info['status'] != 'ok') & (debug_mode == False):\n",
    "                continue\n",
    "            \n",
    "            xs, ys = info['lasso'][1].T\n",
    "            \n",
    "            xs = web['box_x'] * (xs - xmin) / (xmax - xmin) + 0.5\n",
    "            ys = web['box_y'] * (ys - ymin) / (ymax - ymin) + 0.5\n",
    "            \n",
    "            coords = np.ravel([[int(x), int(y)] for x, y in zip(xs, web['box_y'] - ys)]).tolist()\n",
    "            \n",
    "            webinfo = {\n",
    "\n",
    "                'tot': info['tot'],\n",
    "                'bkg': info['bkg'],\n",
    "                'area': f\"{info['area']:,.2f}\",\n",
    "                # 'area': '{:,.2f}'.format(info['area']),\n",
    "                'x': '{:,.2f}'.format(info['centroid_px'][0]),\n",
    "                'y': '{:,.2f}'.format(info['centroid_px'][1]),\n",
    "                'ra': info['ra'],\n",
    "                'dec': info['dec'],\n",
    "                'src': info['src'],\n",
    "                'SN': '{:,.2f}'.format(info['SN']),\n",
    "                'ccd_id': str(ccd),\n",
    "                'bin': 4,\n",
    "                'coords': coords\n",
    "            }\n",
    "            \n",
    "#             if debug_mode: \n",
    "                \n",
    "#                 webinfo['is_good'] = info['is_good']\n",
    "#                 webinfo['shape'] = info['shape']\n",
    "                \n",
    "#                 debug_pars = ['roundness', 'area', 'area_psf', 'area_px', 'kurtosis', 'centrality', 'ks', 'kuiper']\n",
    "                \n",
    "#                 [webinfo.update({_: '{:,.2f}'.format(info[_])}) for _ in debug_pars] \n",
    "                        \n",
    "            web['lassos'][f'{ccd}_{i}'] = webinfo\n",
    "\n",
    "    return web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p39] *",
   "language": "python",
   "name": "conda-env-p39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
